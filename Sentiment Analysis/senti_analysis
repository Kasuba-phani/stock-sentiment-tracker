import pandas as pd
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

# === 1. Load CLEANED Data (Post-Cleaning Pipeline) ===
# Use the cleaned file from previous steps
df = pd.read_csv("cleaned_stock_news.csv")  

# === 2. Initialize VADER with Finance-Specific Lexicon Tweaks ===
analyzer = SentimentIntensityAnalyzer()

# Add financial context words (VADER's default lexicon lacks finance-specific terms)
finance_lexicon = {
    "bullish": 1.5,    # Stronger positive connotation in markets
    "bearish": -1.5,    # Stronger negative connotation
    "rally": 1.3,       # Price surges are strongly positive
    "plummet": -1.7,    # Crashes are strongly negative
    "dividend": 0.5,    # Generally positive for stocks
    "bankrupt": -2.0    # Extreme negative
}
analyzer.lexicon.update(finance_lexicon)

# === 3. Enhanced Sentiment Scoring ===
def get_sentiment(text):
    try:
        scores = analyzer.polarity_scores(str(text))
        return {
            "compound": scores["compound"],
            "positive": scores["pos"],
            "negative": scores["neg"],
            "neutral": scores["neu"]
        }
    except:
        return {"compound": 0, "positive": 0, "negative": 0, "neutral": 1}  # Fallback for errors

# Apply and unpack scores into separate columns
sentiment_data = df["headline"].apply(get_sentiment).apply(pd.Series)
df = pd.concat([df, sentiment_data], axis=1)

# === 4. Dynamic Sentiment Labeling (Adaptive Thresholds) ===
def label_sentiment(row):
    compound = row["compound"]
    if compound >= 0.1:  # Higher threshold for "positive" to reduce false positives
        return "positive"
    elif compound <= -0.1:  # Same for negative
        return "negative"
    else:
        # Check if neutral score is dominant despite compound
        return "neutral" if row["neutral"] > 0.6 else "mixed"

df["sentiment_label"] = df.apply(label_sentiment, axis=1)

# === 5. Add Ticker-Level Sentiment Aggregation ===
ticker_sentiment = df.groupby("ticker")["compound"].agg(["mean", "count"])
ticker_sentiment.rename(columns={
    "mean": "avg_sentiment",
    "count": "news_volume"
}, inplace=True)

# Merge back to original data
df = df.merge(ticker_sentiment, on="ticker", how="left")

# === 6. Save Results with Metadata ===
output_columns = [
    "date", "ticker", "headline", "source",
    "compound", "positive", "negative", "neutral",
    "sentiment_label", "avg_sentiment", "news_volume"
]
df[output_columns].to_csv("news_with_sentiment.csv", index=False)

# === 7. Validation ===
print("\n=== Sentiment Analysis Results ===")
print(f"Total headlines analyzed: {len(df)}")
print(f"Distribution:\n{df['sentiment_label'].value_counts(normalize=True)}")
print("\nSample Output:")
print(df[["ticker", "headline", "compound", "sentiment_label"]].sample(5))
